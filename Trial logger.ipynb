{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10cfed35",
   "metadata": {},
   "source": [
    "# Run 1 - 20221019 (mnist_lr_optim)\n",
    "\n",
    "\n",
    "evaluating basic CNN on mnist as a proof-of-concept and to check that tuning pipeline is working properly. Train mnist for 100 trials to try to get an optimal learning rate on full dataset and 10% of dataset.\n",
    "\n",
    "pytorch lightning does have a learning rate finder, but for the sake of consistency, let's stick with using ray tune for all hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29f6e7",
   "metadata": {},
   "source": [
    "# Plans for future runs\n",
    "\n",
    "- Train models from run 1 and evaluate on mnist test dataset.\n",
    "- Refactor sampling for train/val splits on several datasets (not just mnist). Get splits for subsamples of 75%, 50%, 25%, and 10% of full dataset\n",
    "- repeat run 1 with an early stopping callback - consider training each model for the same number of batches, not the same number of epochs\n",
    "- do hyperparameter optimization for model architecture, optimizer parameters (e.g. type, momentum, etc.), learning rate scheduling, and data augmentation policy\n",
    "- compare these results for several models (e.g. resnet, regnet, yolo, and vision transformer) and datasets (e.g. cifar10, object detection, lane finding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
