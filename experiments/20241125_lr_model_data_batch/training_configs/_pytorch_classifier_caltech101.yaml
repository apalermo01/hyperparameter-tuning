model_cfg:
  model_id: CNN2
  args:
    in_channels: 3
    n_classes: 101
    input_shape: [256, 256]
    ch1: 64
    ch2: 256
    ch3: 512
    lin1: 256
    batch_norm: True
    dropout: True

data_cfg:
  dataset_id: caltech101
  train: True
  batch_size: 16
  num_workers: 3
  use_precomputed_split: True
  split_id: mnist_0_1
  workdir: /home/alex/Documents/git/hyperparameter-tuning/
  data_transofrms:
    - id: resize,
      args: 
        size: 256, 256

loss_cfg:
  loss_id: bce_with_logits_loss
  args:

optimizer_cfg:
  optimizer_id: adam
  args:
    lr: 0.001

flags:
  max_epochs: 10
  default_root_dir: ./experiments/20241125_lr_model_data_batch/

callbacks:
  - early_stop:
      monitor: 'val_loss'
      mode: 'min'
  - plot_metrics:
